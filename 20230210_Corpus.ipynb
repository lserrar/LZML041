{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4221086-529f-452f-9909-2bc7a3386a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#0... Let's check your python version !\n",
    "import sys\n",
    "print(sys.executable)\n",
    "print(sys.version)\n",
    "print(sys.version_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f360481e-9131-47eb-9ed9-35c951eeb79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NumPy is the fundamental package for scientific computing with Python.\n",
    "#1... Install NumPy using pip package in the current Jupyter kernel\n",
    "import sys\n",
    "!{sys.executable} -m pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54757303-efb3-4bd9-b962-4ae74fdbb9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2... Install nltk by using pip command â€“ The first step is to install nltk by using the pip command. \n",
    "!{sys.executable} -m pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bedf385-468e-4cb5-bbf5-50d2c3c8b91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3... import the library NLKT\n",
    "# A new window should open, showing the NLTK Downloader. Click on the File menu and select Change Download Directory. \n",
    "# For central installation, set this to C:\\nltk_data (Windows), /usr/local/share/nltk_data (Mac), or /usr/share/nltk_data (Unix). \n",
    "# Next, download all.\n",
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc33f8c-5eb5-4708-a6e5-55763e76ed5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample usage for wordnet\n",
    "# WordNet is just a NLTK corpus reader, and can be imported like this:\n",
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c90976-e5f1-4fd2-83c6-d4c8722c5fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "wn.langs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074629c3-93f9-484b-aa74-59561ef6516d",
   "metadata": {},
   "outputs": [],
   "source": [
    "wn.synsets('book')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11249c8c-407b-48bb-b36b-4418d95d6e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wn.synsets('livre', lang='fra')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bded4fd1-2971-433a-84a6-7fb8c2ee7738",
   "metadata": {},
   "outputs": [],
   "source": [
    "wn.synsets('espoir', pos=wn.VERB, lang='fra')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06c223a-d876-4a3d-bddd-31bd580ab329",
   "metadata": {},
   "outputs": [],
   "source": [
    "synset_array = wn.synsets('book')\n",
    "synset_array[5].definition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b787f55c-676f-409c-98e2-e629ff506fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for synset in wn.synsets('book'):\n",
    "    print(\"\\tLemma: {}\".format(synset.name()))\n",
    "    print(\"\\tDefinition: {}\".format(synset.definition()))\n",
    "    print(\"\\tExample: {}\".format(synset.examples()))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6f093c-f374-4cc2-80de-a828d43a732c",
   "metadata": {},
   "outputs": [],
   "source": [
    "word=\"lemme\"\n",
    "synset = wn.synsets(word, lang='fra')\n",
    "print('The test word is : ', word)\n",
    "print('Word and Type : ' + synset[0].name())\n",
    "print('Synonym is: ' + synset[0].lemmas()[0].name())\n",
    "print('The meaning of the word : ' + synset[0].definition())\n",
    "print('Example : ' + str(synset[0].examples()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99b3b2a-212b-4e8e-afde-cb18bb0088dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "word=\"token\"\n",
    "synset = wn.synsets(word)\n",
    "print('The test word is : ', word)\n",
    "print('Word and Type : ' + synset[0].name())\n",
    "print('Synonym is: ' + synset[0].lemmas()[0].name())\n",
    "print('The meaning of the word : ' + synset[0].definition())\n",
    "print('Example : ' + str(synset[0].examples()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfe6847-aa51-427c-9c38-7ec67fbc0592",
   "metadata": {},
   "outputs": [],
   "source": [
    "syn = list()\n",
    "ant = list()\n",
    "for synset in wn.synsets(\"stem\"):\n",
    "    for lemma in synset.lemmas():\n",
    "        syn.append(lemma.name())    #add the synonyms\n",
    "        if lemma.antonyms():    #When antonyms are available, add them into the list\n",
    "            ant.append(lemma.antonyms()[0].name())\n",
    "print('Synonyms: ' + str(syn))\n",
    "print('Antonyms: ' + str(ant))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff80189a-ec90-4126-bdee-1bd93030d29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#installer visualisation libraries\n",
    "!{sys.executable} -m pip install networkx[default]\n",
    "!{sys.executable} -m pip install pyvis\n",
    "!{sys.executable} -m pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0978ab11-9753-4940-8bd4-e7c22bf066ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "import networkx as nx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d809240f-539c-44d9-b528-5f916a6ee11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = wn.synset('dog.n.01')\n",
    "w2 = wn.synset('cat.n.01')\n",
    "print(w1.wup_similarity(w2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573aa04d-2a0d-4b00-acf5-334fb01c3a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "from textblob import Word\n",
    "word = Word(\"word\")\n",
    "print (word.synsets[:10])\n",
    "print (word.definitions[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc56e6e-1b70-47b1-b70b-1651b0737cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "G=nx.Graph()\n",
    "\n",
    "w=word.synsets[0]\n",
    "\n",
    "G.add_node(w.name())\n",
    "for h in w.hypernyms():\n",
    "    #print (h)\n",
    "    G.add_node(h.name())\n",
    "    G.add_edge(w.name(),h.name())\n",
    "\n",
    "\n",
    "for h in w.hyponyms():\n",
    "    #print (h)\n",
    "    G.add_node(h.name())\n",
    "    G.add_edge(w.name(),h.name())\n",
    "\n",
    "print (G.nodes(data=True))\n",
    "plt.show()\n",
    "plt.rcParams['figure.figsize'] = [21, 5]\n",
    "nx.draw(G, width=1, with_labels=True, node_color=\"#007ed9\")\n",
    "plt.savefig(\"path.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fefcc44-c0b7-4951-9f2b-850323f9895c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to see all other layouts: https://networkx.org/documentation/stable/reference/generated/networkx.drawing.layout.random_layout.html\n",
    "nx.draw(G, pos=nx.spiral_layout(G))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea08bbdf-9c0e-4d40-8073-89629df3eca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets explore the Guttenberg in NLKT !\n",
    "nltk.download('gutenberg')\n",
    "nltk.corpus.gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081afa47-9af5-471e-a680-6067755d8f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "moby_dick = nltk.corpus.gutenberg.words( 'melville-moby_dick.txt')\n",
    "len(moby_dick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ff8ad0-881c-4b68-a714-6bd2752c0a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "for text in nltk.corpus.gutenberg.fileids():\n",
    "    print('# of words in ',text,'is: ', len(nltk.corpus.gutenberg.words( text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41be7769-7870-4ac1-847d-5d7aaaab4f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets load a specific book from Guttenberg website \n",
    "# you will need to leverage the requests package\n",
    "import requests\n",
    "#choose a book in Gutenberg project website the https://www.gutenberg.org/ebooks/5258 and get the reference number of the book, here 5258 !\n",
    "r = requests.get(r'https://www.gutenberg.org/cache/epub/5258/pg5258.txt')\n",
    "Zarathoustra_Nietzsche = r.text\n",
    "\n",
    "# first, remove unwanted new line and tab characters from the text\n",
    "for char in [\"\\n\", \"\\r\", \"\\d\", \"\\t\"]:\n",
    "    Zarathoustra_Nietzsche = Zarathoustra_Nietzsche.replace(char, \" \")\n",
    "#print number of characters in the book\n",
    "print(len(Zarathoustra_Nietzsche))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098a4855-079d-4a48-b761-4c5b0f5fe002",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To see the project gutenburg introduction and footnotes\n",
    "print(Zarathoustra_Nietzsche[0:910]) \n",
    "print('-------------------------------------------------') \n",
    "print(Zarathoustra_Nietzsche[637986:639986]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacf318f-9596-48a4-bc88-8b549a259987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can also subset for the book text\n",
    "# (removing the project gutenburg introduction/footnotes)\n",
    "Zarathoustra_Nietzsche = Zarathoustra_Nietzsche[911:635986]\n",
    "#print(Zarathoustra_Nietzsche)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa6bb2e-9cef-474d-88a9-259b4855345e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets Tokenize the Text\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import re\n",
    "\n",
    "# Choose your Text\n",
    "text = Zarathoustra_Nietzsche\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bacf1a-6405-42d9-8e1f-a7de4d127c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens =word_tokenize(text, language=\"french\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c7d1e5-a825-4056-a56f-6f57c3e5372a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the 20 most commons tokens\n",
    "from collections import Counter\n",
    "print(Counter(tokens).most_common(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4964a40-68e9-49ab-bd1d-98325d12df0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets remove punctiation !\n",
    "remove = re.sub(r'[^\\w\\s]', '', text)\n",
    "#print(\"updated text with no punctuations :\", remove)\n",
    "tokens =word_tokenize(remove, language=\"french\")\n",
    "print(Counter(tokens).most_common(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba18dd8-9682-4068-bc9a-7b61e6fa47b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets remove Stopwords !\n",
    "french_stopwords = set(stopwords.words('french'))\n",
    "filtre_stopfr =  lambda text: [token for token in text if token.lower() not in french_stopwords]\n",
    "\n",
    "tokens_Filtered=filtre_stopfr( tokens)\n",
    "print(Counter(tokens_Filtered).most_common(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d8c5f9-bfd7-4811-886f-fdb251eb424d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do you wantg to exclude anything else?\n",
    "Stop_words=['plus']\n",
    "for x in Stop_words:\n",
    "    french_stopwords.add(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17304319-021e-4b39-8451-0716ddf4209e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_Filtered=filtre_stopfr( tokens)\n",
    "print(Counter(tokens_Filtered).most_common(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34488df3-4bba-47c9-ab8b-9f698e81609e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stemmatization\n",
    "# Now it would be interesting to group words with the same syntactic root, for this we will use the stemmatization function of NLTK: stem(). 5\n",
    "stemmer=nltk.stem.snowball.FrenchStemmer()\n",
    "#stemmer = FrenchStemmer()\n",
    "\n",
    "Stemmed_Text =  lambda text: [stemmer.stem(token) for token in text]\n",
    "\n",
    "#for w in tokens_Filtered:\n",
    " #   print(stemmer.stem(w))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53d8fb6-0bf3-4313-aa9d-88c52196377b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_stems=Stemmed_Text( tokens_Filtered)\n",
    "print(Counter(tokens_stems).most_common(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6e10ec-490c-4037-8fb2-0489ca6e83a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!{sys.executable} -m pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fe0f6e-c49b-45c4-b4c8-75f0ed694b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "wordcloud = WordCloud(width= 1000, height = 600, max_words=100,\n",
    "                      random_state=1, background_color='White', colormap='cubehelix',\n",
    "                      collocations=False, stopwords = STOPWORDS).generate(text)\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(wordcloud) \n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1375cf20-c7ff-42b1-8ce8-3fd5b383e914",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = stopwords.words('french')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ae5498-d2bb-485e-b7c2-d8004ab3194e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stopwords )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be402d9-6e2d-4a20-9d7e-91ba469aa5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(width= 1000, height = 600, max_words=100,\n",
    "                      random_state=1, background_color='Black', colormap='Paired',\n",
    "                      collocations=False, stopwords = stopwords).generate(text)\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.imshow(wordcloud) \n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8727ce19-7571-4a0d-abd1-a561e41821a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "mask = np.array(Image.open(\"Nietzsche.jpg\"))\n",
    "mask.shape\n",
    "# Generating colors from image\n",
    "image_colors = ImageColorGenerator(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25e00b9-3e00-4224-bac0-75cc516ddab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(width= 1000, height = 600, max_words=700,\n",
    "                      random_state=1, background_color='Yellow', colormap='winter_r',\n",
    "                      collocations=False, stopwords = stopwords, mask = mask).generate(text)\n",
    "plt.figure(figsize=(5, 13))\n",
    "plt.imshow(wordcloud) \n",
    "#plt.imshow(wordcloud.recolor(color_func=image_colors), interpolation ='bilinear') # Using the color function here\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(mask) \n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa0cbf1-7e86-4bd1-9797-97e9fc9d4f88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
